{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.io.json import json_normalize\n",
    "import pymongo\n",
    "import warnings\n",
    "from bs4 import BeautifulSoup\n",
    "import datetime\n",
    "from lxml import etree\n",
    "from itertools import chain\n",
    "from lxml import html\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='bs4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = os.getenv(\"DATA_DIR\")\n",
    "CONFIG = os.getenv(\"CONFIG\")\n",
    "blacklist_path = os.path.join(CONFIG, 'document_types_excluded_from_the_topic_taxonomy.yml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "mongo_client = pymongo.MongoClient(\"mongodb://localhost:27017/\")\n",
    "\n",
    "content_store_db = mongo_client[\"content_store\"]\n",
    "content_store_collection = content_store_db[\"content_items\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_excluded_document_types():\n",
    "    with open(blacklist_path, 'r') as f:\n",
    "        return yaml.safe_load(f)['document_types']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['about',\n",
       " 'about_our_services',\n",
       " 'access_and_opening',\n",
       " 'business_support_finder',\n",
       " 'coming_soon']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BLACKLIST_DOCUMENT_TYPES = get_excluded_document_types()\n",
    "BLACKLIST_DOCUMENT_TYPES[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT_PROJECTION = {\n",
    "    \"expanded_links.organisations\": 1,\n",
    "    \"expanded_links.primary_publishing_organisation\": 1,\n",
    "    \"expanded_links.worldwide_organisations\": 1,\n",
    "    \"expanded_links.supporting_organisations\": 1,\n",
    "    \"expanded_links.original_primary_publishing_organisation\": 1,\n",
    "    \"details.body\": 1,\n",
    "    \"details.brand\": 1,  # no documents found?\n",
    "    \"details.documents\": 1,\n",
    "    \"details.final_outcome_detail\": 1,\n",
    "    \"details.final_outcome_documents\": 1,\n",
    "    \"details.government\": 1,\n",
    "    \"details.headers\": 1,\n",
    "    \"details.introduction\": 1,\n",
    "    \"details.introductory_paragraph\": 1,\n",
    "    \"details.licence_overview\": 1,\n",
    "    \"details.licence_short_description\": 1,\n",
    "    \"details.logo\": 1,\n",
    "    \"details.metadata\": 1,\n",
    "    \"details.more_information\": 1,\n",
    "    \"details.need_to_know\": 1,\n",
    "    \"details.other_ways_to_apply\": 1,\n",
    "    \"details.summary\": 1,\n",
    "    \"details.ways_to_respond\": 1,\n",
    "    \"details.what_you_need_to_know\": 1,\n",
    "    \"details.will_continue_on\": 1,\n",
    "    \"details.parts\": 1,\n",
    "    \"details.collection_groups\": 1,\n",
    "    \"details.transaction_start_link\": 1,\n",
    "    \"title\":1,\n",
    "    \"description\":1,\n",
    "    \"document_type\": 1,\n",
    "    \"content_id\": 1}\n",
    "\n",
    "FILTER_BASIC = {\"$and\": [\n",
    "    {\"document_type\": {\"$nin\": BLACKLIST_DOCUMENT_TYPES}},\n",
    "    {\"phase\": \"live\"}]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# content_items = content_store_collection.find(FILTER_BASIC, TEXT_PROJECTION)\n",
    "# # rowlist = []\n",
    "# # for i,item in enumerate(content_items):\n",
    "# #     if i < 10:\n",
    "# #         rowlist.append(item)\n",
    "# #     else:\n",
    "# #         break\n",
    "# # df = pd.DataFrame(rowlist)\n",
    "# # df\n",
    "# # df = json_normalize(list(content_items)[0:10])\n",
    "# # df\n",
    "# df = pd.DataFrame([item for item in content_items][0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['orgs_id'] = df['expanded_links'].map(extract_org_id)\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_org_id(data):\n",
    "    return {key:[v['content_id'] for v in value] for key,value in data.items()}\n",
    "\n",
    "def extract_org_title(data):\n",
    "    return {key:[v['title'] for v in value] for key,value in data.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'organisations': ['Education and Skills Funding Agency'],\n",
       " 'primary_publishing_organisation': ['Government Digital Service']}"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_org_title(df.iloc[0].expanded_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_html(text):\n",
    "    \"\"\"\n",
    "    Checks whether text is html or not\n",
    "    :param text: string\n",
    "    :return: bool\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return bool(BeautifulSoup(text, \"html.parser\").find())\n",
    "    # might be fine to except all exceptions here, as it's a low-level function\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "def extract_text_from_content_details(data):\n",
    "    \"\"\"\n",
    "    Recurses through lists and dicts to find html and then extract links BE VERY CAREFUL AND PASS IN LINKS, otherwise old links may persist in the list\n",
    "    :param data: This function can accept a nested list or dict, or string\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    if type(data) == list:\n",
    "        return \"\".join(list(chain.from_iterable([\n",
    "            extract_text_from_content_details(item)\n",
    "            for item in data\n",
    "        ])))\n",
    "    elif type(data) == dict:\n",
    "        return extract_text_from_content_details(list(data.values()))\n",
    "    elif is_html(data):\n",
    "        return extract_text(data)\n",
    "    else:\n",
    "        return \"\"\n",
    "\n",
    "def extract_text(body):\n",
    "    \"\"\"\n",
    "    Extract text from html body\n",
    "    :param body: <str> containing html.\n",
    "    \"\"\"\n",
    "    # TODO: Tidy this up!\n",
    "    r = None\n",
    "    # body != \"\\n\" and\n",
    "    if body and body != \"\\n\" and not body.isspace():\n",
    "        try:\n",
    "            # print(\"this is\", body)\n",
    "            tree = etree.HTML(body)\n",
    "            r = tree.xpath('//text()')\n",
    "            r = ' '.join(r)\n",
    "            r = r.strip().replace('\\n', ' ').replace('\\r', ' ').replace('\\t', ' ')\n",
    "            r = r.replace('\\n', ' ').replace(',', ' ')\n",
    "            # r = r.lower()\n",
    "            r = ' '.join(r.split())\n",
    "        except ValueError:\n",
    "            print(\"exception @ extract:\", type(body), body)\n",
    "    if not r:\n",
    "        r = ' '\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_page_data(mongodb_collection):\n",
    "    \"\"\"\n",
    "    Queries a MongoDB collection, get specific fields from details using TEXT_PROJECTION, converts this cursor to a DataFrame, with all details fields in one list column\n",
    "    :param mongodb_collection:\n",
    "    :return: pandas DataFrame with: _id (base_path), content_id, and all_details list column\n",
    "    \"\"\"\n",
    "    content_items = mongodb_collection.find(FILTER_BASIC, TEXT_PROJECTION)\n",
    "    row_list = []\n",
    "    \n",
    "    for i,item in enumerate(content_items):\n",
    "#         if i < 100:\n",
    "        item['details'] = extract_text_from_content_details(item['details'])\n",
    "        item['description'] = item['description']['value']\n",
    "        item['orgs_id'] = extract_org_id(item['expanded_links'])\n",
    "        item['orgs_id'] = extract_org_id(item['expanded_links'])\n",
    "        item['orgs_title'] = extract_org_title(item['expanded_links'])\n",
    "        del item['expanded_links']\n",
    "        row_list.append(item)\n",
    "#         else: \n",
    "#             break\n",
    "        if i % 20000==0:\n",
    "            print(datetime.datetime.now().strftime(\"%H:%M:%S\"),\":\",i)\n",
    "\n",
    "    return row_list\n",
    "\n",
    "def df_wrapper(mongodb_collection):\n",
    "    data_list = get_page_data(mongodb_collection)\n",
    "    df = pd.DataFrame(data_list)\n",
    "    df.rename(columns={'_id':'base_path','details':'text'}, inplace=True)\n",
    "    return df[['base_path', 'content_id', 'title', 'description', \n",
    "               'document_type', 'orgs_id', 'orgs_title', 'text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23:17:12 : 0\n",
      "23:18:06 : 20000\n",
      "23:18:33 : 40000\n",
      "23:19:41 : 60000\n",
      "23:20:24 : 80000\n"
     ]
    }
   ],
   "source": [
    "df = df_wrapper(content_store_collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(os.path.join(DATA_DIR, \"preprocessed_content_store.csv.gz\"), \n",
    "          index=False, \n",
    "          compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
